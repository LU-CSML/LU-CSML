<p>
<h2>The Scalable Langevin Exact Algorithm: Bayesian Inference for Big Data</h2>


I'll be talking about the recently arxived ScaLE paper, which introduces a class of Monte Carlo algorithms which are based upon simulating a Markov process whose quasi-stationary distribution coincides with the distribution of interest. This differs fundamentally from, say, current Markov chain Monte Carlo in which we simulate a Markov chain whose stationary distribution is the target. We show how to approximate distributions of interest by carefully combining sequential Monte Carlo methods with methodology for the exact simulation of diffusions. Our methodology is particularly promising in that it is applicable to the same class of problems as gradient based Markov chain Monte Carlo algorithms but entirely circumvents the need to conduct Metropolis-Hastings type accept/reject steps whilst retaining exactness: we have theoretical guarantees that we recover the correct limiting target distribution. Furthermore, this methodology is highly amenable to big data problems. By employing a modification to existing naive subsampling techniques we can obtain an algorithm which is still exact but has sub-linear iterative cost as a function of data size.
